## 基本信息

姓名：简历本

年龄：26

电话：ccc

邮箱：xxx@gmail.com

经验：3年

意向：大数据运维工程师

## 教育背景

时间：2012-09 到 2016-06		学校：简历本科技大学 

专业：计算机科学与技术		    学历：本科

## 专业技能

理解Hadoop、Kafka和Spark等主流大数据组件的核心框架及其工作原理

熟悉数据仓库建设、集成和管理等数据仓库基本理论

熟练使用Hadoop、Flume、Sqoop、Impala、Hue、Kettle、Oozie等常用大数据组件

熟悉Kerberos、Sentry和Ranger等安全访问控制组件

熟悉MySQL/PostgreSQL基本的SQL语句、日常配置和应用调优

熟练使用Linux操作系统；熟练Shell开发；熟悉Python开发

熟练使用Docker和Docker file编写；熟悉Docker compose编排和Kubernetes编排

熟练使用Maven、Git和Jenkins等开发工具

## 工作经历

工作时间：2016-07 - 至今

公司名称：简历本信息技术有限公司 | 所在部门： | 所在岗位：大数据开发工程师

工作内容：
1.大数据平台（CDH/HDP/Kafka）集群规划及部署、高可用配置、访问控制、扩容缩容、性能优化和日常维护等

2.负责Hive数据仓库的数据采集、数据清洗、数据存储、数据维护及数据仓库优化工作

3.负责Kylin多维度数据分析系统的数据采集、模型设计、模型构建、cube剪枝优化、cube rowKey优化等

4.负责离线计算Spark DataFrame代码编写、测试、部署和调优

## 项目经历





## 个人评价



